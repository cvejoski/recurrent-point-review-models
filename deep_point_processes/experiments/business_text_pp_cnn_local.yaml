name: yelp19_shopping_business_text_pp_cnn_1x16
num_runs: 1
num_workers: 1
gpus: !!python/tuple [1]
seed: 1
dtype: float32

model:
  module: dpp.models
  name: TextTPP
  args:
    attention: true
    attention_layer:
      module: gentext.models.blocks
      name: DynamicAttentionLayer
      args:
        attention_dim: 128
    tpp_model:
      module: dpp.models
      name: BoWTPP
      args:
        input_dim: 2
        language_embedding_size: 1024 # this should match the size of the output of the text model
        embedding_size: 64 # mark embedding size of the mtpp
        inv_sampling_size: 1000
        cell_type:
          module: torch.nn
          name: LSTM
          args:
            hidden_size: [64]
            num_layers: 1
            dropout: 0
        n_markers: 0
        ignore_index: -1
        metrics: !!python/tuple
          - module: tyche.loss
            name: MSELoss
            args:
              reduction: sum
    language_model:
      module: gentext.models.languagemodels
      name: BasicLM
      args:
        train_word_embeddings: false
        decoder:
          module: gentext.models.blocks
          name: DecoderCNN
          args:
            cnn_block: "residual_bottleneck"
            kernel_sizes: !!python/tuple [3, 3, 3, 3, 3]
            stride: !!python/tuple [1, 1, 1, 1, 1]
            padding: !!python/tuple [1, 2, 4, 8, 16]
            dilation: !!python/tuple [1, 2, 4, 8, 16]
            output_channels: !!python/tuple [1024, 1024, 1024, 1024, 1024]
            conv_noise: false
            affine_noise: false
            nonlinearity: "ReLU"
            n_layers_per_residual_block: 2
            n_residual_blocks: 2
            normalization: "weight_norm"
            max_len: 80

data_loader:
  module: dpp.data.loaders
  name: TextPointLoader
  args:
    server: localhost:27017
    db: yelp
    data_collection: review_shopping_by_business
    emb_dim: glove.6B.300d
    voc_size: 5000
    min_freq: 5
    path_to_vectors: "/home/bit/sanchez/Projects/GENTEXT/data/"
    batch_size: 128
    bptt_len: 20
    time_fix_len: null
    text_fix_len: 80
    t_max: null

optimizer:
  module: torch.optim
  name: Adadelta
  args:
    lr: 1.0

language_optimizer:
  module: torch.optim
  name: Adam
  args:
    lr: 0.0002


trainer:
  module: dpp.trainer
  name: PointTextTrainer
  args:
    bm_metric: MSELoss
    save_after_epoch: 10
    reconstruction_every: 50
    num_rec_sentences: 20
    schedulers: !!python/tuple
      - module: tyche.utils.param_scheduler
        name: ConstantScheduler
        label: beta_scheduler
        args:
          beta: 1.
  epochs: 50

  save_dir: "/home/bit/sanchez/results/deep_point_processes/results/saved/"
  logging:
    tensorboard_dir: "/home/bit/sanchez/results/deep_point_processes/results/logging/tensorboard/"
    logging_dir: "/home/bit/sanchez/results/deep_point_processes/results/logging/raw/"
    formatters:
      verbose: "%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s"
      simple: "%(levelname)s %(asctime)s %(message)s"